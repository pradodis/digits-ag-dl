
# ğŸ§  Deep Learning com Algoritmo GenÃ©tico (AG) para ClassificaÃ§Ã£o de DÃ­gitos Manuscritos âœï¸

ğŸ“Œ RepositÃ³rio: https://github.com/araujofran/digits-ag-dl

Este projeto ğŸš€ combina Deep Learning com Algoritmos GenÃ©ticos (AG) para otimizar a camada de uma Rede Neural na classificaÃ§Ã£o de dÃ­gitos do dataset digits (0â€“9) ğŸ”¢. Nosso objetivo Ã© explorar como o AG pode encontrar os melhores pesos para uma parte da rede, enquanto o restante aprende do jeito tradicional! âœ¨

---

## ğŸŒŸ VisÃ£o Geral do Projeto

- PreparaÃ§Ã£o dos Dados ğŸ“Š  
  Carregar, normalizar e dividir o dataset digits.  

- Arquitetura da Rede Neural ğŸ—ï¸  
  Definir a MLP, escolhendo uma camada para ser otimizada pelo AG.  

- OtimizaÃ§Ã£o HÃ­brida ğŸ§¬âš™ï¸  
  Usar AG para evoluir os pesos da camada selecionada, enquanto RMSprop ajusta o resto.  

- AvaliaÃ§Ã£o e VisualizaÃ§Ã£o ğŸ¯ğŸ“ˆ  
  Avaliar acurÃ¡cia, visualizar evoluÃ§Ã£o da aptidÃ£o e distribuiÃ§Ã£o de pesos.  

---

## ğŸ“– Como Funciona (Detalhes do CÃ³digo)

### 0. Setup Inicial e ImportaÃ§Ãµes ğŸ› ï¸
Importamos as bibliotecas essenciais: NumPy, TensorFlow/Keras, Scikit-learn, Pandas, Matplotlib e Seaborn.

### 1. FunÃ§Ãµes Base e Auxiliares ğŸ‘·â€â™€ï¸
- **load_and_preprocess_data()**  
  Carrega o dataset, normaliza pixels (0â€“16 para 0â€“1) e divide treino/teste.  

- **build_model_for_ag_fitness()**  
  ConstrÃ³i a MLP com:  
  - Input(shape=(64,))  
  - Camada otimizada pelo AG: `Dense(128, activation='relu')` (congelada apÃ³s receber pesos do AG)  
  - `Dense(64, activation='relu')`  
  - `Dense(10, activation='softmax')`  
  Compila com `sparse_categorical_crossentropy` e `rmsprop`.  

- **flatten_weights() / unflatten_weights()**  
  Converter pesos entre lista de matrizes e vetor unidimensional.

### 2. PreparaÃ§Ã£o dos Dados e ParÃ¢metros ğŸ“
- Carregamento e divisÃ£o, separando um hold-out para avaliaÃ§Ã£o de aptidÃ£o.  
- `individual_size`: tamanho do â€œDNAâ€ (pesos + vieses) que o AG vai evoluir.  
- ParÃ¢metros do AG: populaÃ§Ã£o, geraÃ§Ãµes, taxa de mutaÃ§Ã£o, crossover, elitismo.

### 3. FunÃ§Ãµes do Algoritmo GenÃ©tico ğŸ§¬
- **generate_initial_population()**: inicia populaÃ§Ã£o com pesos aleatÃ³rios.  
- **evaluate_fitness()**: constrÃ³i modelo para cada indivÃ­duo, treina outras camadas por 5 Ã©pocas e mede acurÃ¡cia.  
- **select_parents()**: escolhe elites e faz torneios para selecionar pais.  
- **crossover()**: combina â€œDNAâ€ de dois pais para gerar filhos.  
- **mutate()**: altera aleatoriamente alguns genes (pesos) para manter diversidade.  
- **replace_population()**: substitui geraÃ§Ãµes antigas pelas novas.

### 4. Loop Principal do AG: A Grande EvoluÃ§Ã£o! ğŸ“ˆ
Em cada geraÃ§Ã£o: avalia, seleciona, cruza, muta e substitui. Registramos aptidÃ£o mÃ¡xima e mÃ©dia para visualizar progresso.

### 5. AnÃ¡lise de Progresso (VisualizaÃ§Ãµes) ğŸ‘€
- GrÃ¡fico de AptidÃ£o: evoluÃ§Ã£o da acurÃ¡cia ao longo das geraÃ§Ãµes.  
- Histogramas de Pesos: comparaÃ§Ã£o entre primeira e Ãºltima geraÃ§Ã£o.

### 6. AvaliaÃ§Ã£o Final do Modelo HÃ­brido ğŸ†
- O melhor indivÃ­duo Ã© fixado na rede.  
- As outras camadas fazem um treino final de 50 Ã©pocas.  
- MÃ©tricas de acurÃ¡cia e perda sÃ£o avaliadas no conjunto de teste.  
- SumÃ¡rio em tabela dos resultados.

---

## ğŸ’ª Por Que Usar AG com Deep Learning?

- ExploraÃ§Ã£o Poderosa: AGs encontram soluÃ§Ãµes em espaÃ§os complexos onde otimizadores tradicionais podem falhar.  
- Robustez: geram soluÃ§Ãµes diversas e resistentes a mÃ­nimos locais.  
- OtimizaÃ§Ã£o de HiperparÃ¢metros/Arquitetura: ideal para ajustar partes sensÃ­veis de uma rede.  

---

## ğŸš€ Como Rodar o Projeto

1. Instale as bibliotecas:
   ```bash
   pip install numpy tensorflow keras scikit-learn pandas matplotlib seaborn
   ```

2. Clone o repositÃ³rio e execute:
   ```bash
   git clone https://github.com/araujofran/digits-ag-dl.git
   cd digits-ag-dl
   python main.py
   ```

3. Ou abra o notebook em Jupyter/Colab.

---

## ğŸ’¡ PrÃ³ximos Passos (Ideias para Melhorar)

- Compare contra uma rede sem AG para medir ganhos de performance.  
- Experimente diferentes parÃ¢metros de AG (populaÃ§Ã£o, geraÃ§Ãµes, taxas).  
- Otimize mÃºltiplas camadas ou toda a arquitetura pelo AG.  
- Visualize como o AG altera as representaÃ§Ãµes internas dos dados.  
```
